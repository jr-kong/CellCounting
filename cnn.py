from __future__ import annotations

import argparse
import csv
import json
import random
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Sequence, Tuple

import numpy as np
import matplotlib

matplotlib.use("Agg")
import matplotlib.pyplot as plt
import torch
from torch import nn
from torch.utils.data import DataLoader, Dataset, Subset


@dataclass(frozen=True)
class SampleEntry:
    npz_path: Path
    count: int


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Train a simple CNN regressor on preprocessed cell-count data."
    )
    parser.add_argument(
        "--metadata",
        type=Path,
        default=Path("/content/drive/MyDrive/CellCounting/processed/metadata.csv"),
        help="CSV generated by data_preprocess.py.",
    )
    parser.add_argument(
        "--root",
        type=Path,
        default=Path("/content/drive/MyDrive/CellCounting/processed"),
        help="Root directory containing sample NPZ files.",
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=4,
        help="Mini-batch size.",
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=10,
        help="Number of training epochs.",
    )
    parser.add_argument(
        "--learning-rate",
        type=float,
        default=1e-3,
        help="Adam learning rate.",
    )
    parser.add_argument(
        "--val-split",
        type=float,
        default=0.1,
        help="Fraction of samples reserved for validation (0 disables split).",
    )
    parser.add_argument(
        "--test-split",
        type=float,
        default=0.1,
        help="Fraction of samples reserved for final test evaluation.",
    )
    parser.add_argument(
        "--num-workers",
        type=int,
        default=0,
        help="Dataloader worker processes.",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="Random seed for shuffling and weight init.",
    )
    parser.add_argument(
        "--device",
        type=str,
        default="cuda" if torch.cuda.is_available() else "cpu",
        help="Training device (cuda or cpu).",
    )
    parser.add_argument(
        "--experiment-root",
        type=Path,
        default=Path("/content/drive/MyDrive/CellCounting/experiments"),
        help="Directory where run artifacts will be stored.",
    )
    parser.add_argument(
        "--run-name",
        type=str,
        default=None,
        help="Optional identifier for this training run (defaults to timestamp).",
    )
    return parser.parse_args()


def load_metadata(metadata_path: Path, root: Path) -> List[SampleEntry]:
    entries: List[SampleEntry] = []
    with metadata_path.open("r", newline="", encoding="utf-8") as fh:
        reader = csv.DictReader(fh)
        for row in reader:
            sample_rel = Path(row["sample_npz"])
            count = int(row["cell_count"])
            if sample_rel.is_absolute():
                sample_path = sample_rel
            elif sample_rel.parts and sample_rel.parts[0] == root.name:
                sample_path = (root.parent / sample_rel).resolve()
            else:
                sample_path = (root / sample_rel).resolve()
            entries.append(SampleEntry(sample_path, count))
    if not entries:
        raise SystemExit(f"No samples found via {metadata_path}.")
    return entries


class DatasetClass(Dataset):
    def __init__(self, entries: Sequence[SampleEntry]):
        self.entries = list(entries)

    def __len__(self) -> int:
        return len(self.entries)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        entry = self.entries[idx]
        with np.load(entry.npz_path) as data:
            image = data["image"].astype(np.float32)
            count = float(np.array(data["count"]).item())
        image_tensor = torch.from_numpy(image)
        target = torch.tensor(count, dtype=torch.float32)
        return image_tensor, target


class CNN(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d(1),
        )
        self.regressor = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 1),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        feats = self.features(x)
        return self.regressor(feats).squeeze(1)


def split_indices(
    n_samples: int, val_split: float, test_split: float, seed: int
) -> Tuple[List[int], List[int], List[int]]:
    if val_split < 0 or test_split < 0:
        raise SystemExit("Splits must be non-negative.")
    if val_split + test_split >= 1.0:
        raise SystemExit("val_split + test_split must be less than 1.")

    indices = list(range(n_samples))
    random.Random(seed).shuffle(indices)

    test_count = int(round(n_samples * test_split))
    val_count = int(round(n_samples * val_split))

    test_indices = indices[:test_count]
    val_indices = indices[test_count : test_count + val_count]
    train_indices = indices[test_count + val_count :]

    if not train_indices:
        raise SystemExit("Splits leave no training samples.")

    return train_indices, val_indices, test_indices


def evaluate(model: nn.Module, loader: DataLoader, device: torch.device) -> Tuple[float, float]:
    model.eval()
    mse = 0.0
    mae = 0.0
    total = 0
    criterion = nn.MSELoss(reduction="sum")
    with torch.no_grad():
        for images, targets in loader:
            images = images.to(device)
            targets = targets.to(device)
            preds = model(images)
            mse += criterion(preds, targets).item()
            mae += torch.abs(preds - targets).sum().item()
            total += targets.numel()
    if total == 0:
        return float("nan"), float("nan")
    return mse / total, mae / total


def collect_predictions(
    model: nn.Module, loader: DataLoader, device: torch.device
) -> Tuple[np.ndarray, np.ndarray]:
    model.eval()
    preds_batches: List[np.ndarray] = []
    targets_batches: List[np.ndarray] = []
    with torch.no_grad():
        for images, targets in loader:
            images = images.to(device)
            targets = targets.to(device)
            outputs = model(images)
            preds_batches.append(outputs.detach().cpu().numpy())
            targets_batches.append(targets.detach().cpu().numpy())
    if not preds_batches:
        return np.empty(0, dtype=np.float32), np.empty(0, dtype=np.float32)
    preds = np.concatenate(preds_batches, axis=0).astype(np.float32, copy=False)
    targets = np.concatenate(targets_batches, axis=0).astype(np.float32, copy=False)
    return targets, preds


def create_run_dir(root: Path, run_name: Optional[str]) -> Path:
    root = root.resolve()
    root.mkdir(parents=True, exist_ok=True)
    if run_name:
        base = run_name.strip().replace(" ", "_")
        base = base or datetime.now().strftime("%Y%m%d_%H%M%S")
    else:
        base = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_dir = root / base
    suffix = 1
    while run_dir.exists():
        run_dir = root / f"{base}_{suffix:02d}"
        suffix += 1
    run_dir.mkdir()
    return run_dir


def serialize_config(
    args: argparse.Namespace,
    device: torch.device,
    train_count: int,
    val_count: int,
    test_count: int,
) -> dict:
    config = {}
    for key, value in vars(args).items():
        if isinstance(value, Path):
            config[key] = str(value)
        else:
            config[key] = value
    config["resolved_device"] = device.type
    config["train_samples"] = int(train_count)
    config["val_samples"] = int(val_count)
    config["test_samples"] = int(test_count)
    return config


def main() -> None:
    args = parse_args()

    torch.manual_seed(args.seed)
    np.random.seed(args.seed)
    random.seed(args.seed)

    entries = load_metadata(args.metadata, args.root)
    dataset = DatasetClass(entries)

    train_idx, val_idx, test_idx = split_indices(
        len(dataset), args.val_split, args.test_split, args.seed
    )
    train_subset = Subset(dataset, train_idx)
    val_subset = Subset(dataset, val_idx) if val_idx else None
    test_subset = Subset(dataset, test_idx) if test_idx else None

    device = torch.device(args.device)
    use_cuda = device.type == "cuda"

    train_loader = DataLoader(
        train_subset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=use_cuda,
    )
    val_loader = (
        DataLoader(
            val_subset,
            batch_size=args.batch_size,
            shuffle=False,
            num_workers=args.num_workers,
            pin_memory=use_cuda,
        )
        if val_subset
        else None
    )
    test_loader = (
        DataLoader(
            test_subset,
            batch_size=args.batch_size,
            shuffle=False,
            num_workers=args.num_workers,
            pin_memory=use_cuda,
        )
        if test_subset
        else None
    )

    model = CNN().to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)
    criterion = nn.MSELoss()

    run_dir = create_run_dir(args.experiment_root, args.run_name)
    history: List[dict] = []

    config = serialize_config(
        args,
        device,
        train_count=len(train_subset),
        val_count=len(val_subset) if val_subset else 0,
        test_count=len(test_subset) if test_subset else 0,
    )
    with (run_dir / "config.json").open("w", encoding="utf-8") as cfg_file:
        json.dump(config, cfg_file, indent=2)

    for epoch in range(1, args.epochs + 1):
        model.train()
        epoch_loss = 0.0
        total_steps = len(train_loader)
        next_print_fraction = 0.1
        for step_idx, (images, targets) in enumerate(train_loader, 1):
            images = images.to(device)
            targets = targets.to(device)
            optimizer.zero_grad()
            preds = model(images)
            loss = criterion(preds, targets)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item() * targets.size(0)

            progress = step_idx / total_steps if total_steps else 1.0
            if progress >= next_print_fraction or step_idx == total_steps:
                print(
                    f"Epoch {epoch:03d} | "
                    f"{progress * 100:6.2f}% of epoch complete "
                    f"(step {step_idx}/{total_steps})"
                )
                next_print_fraction += 0.1

        train_mse = epoch_loss / len(train_subset)
        msg = f"Epoch {epoch:03d} - train MSE: {train_mse:.4f}"

        if val_loader is not None:
            val_mse, val_mae = evaluate(model, val_loader, device)
            msg += f", val MSE: {val_mse:.4f}, val MAE: {val_mae:.4f}"
        else:
            val_mse, val_mae = float("nan"), float("nan")

        percent = (epoch / args.epochs) * 100.0
        print(f"{percent:6.2f}% | {msg}")
        history.append(
            {
                "epoch": epoch,
                "train_mse": float(train_mse),
                "val_mse": float(val_mse),
                "val_mae": float(val_mae),
            }
        )

    metrics_path = run_dir / "metrics.csv"
    with metrics_path.open("w", newline="", encoding="utf-8") as metrics_file:
        writer = csv.DictWriter(
            metrics_file,
            fieldnames=["epoch", "train_mse", "val_mse", "val_mae"],
        )
        writer.writeheader()
        writer.writerows(history)

    scatter_path = None
    test_metrics_path = None
    if test_loader is not None:
        test_targets, test_preds = collect_predictions(model, test_loader, device)
        if test_targets.size > 0:
            diff = test_preds - test_targets
            test_mse = float(np.mean(diff ** 2))
            test_mae = float(np.mean(np.abs(diff)))
            print(f"Test MSE: {test_mse:.4f} | Test MAE: {test_mae:.4f}")
            test_metrics_path = run_dir / "test_metrics.json"
            with test_metrics_path.open("w", encoding="utf-8") as fh:
                json.dump({"mse": test_mse, "mae": test_mae}, fh, indent=2)

            scatter_path = run_dir / "test_scatter.png"
            fig, ax = plt.subplots(figsize=(6, 6))
            ax.scatter(test_targets, test_preds, s=12, alpha=0.6, edgecolors="none")
            min_val = float(min(test_targets.min(), test_preds.min()))
            max_val = float(max(test_targets.max(), test_preds.max()))
            ax.plot([min_val, max_val], [min_val, max_val], color="gray", linestyle="--")
            ax.set_xlabel("True Count")
            ax.set_ylabel("Predicted Count")
            ax.set_title("Test Predictions vs. Ground Truth")
            ax.grid(True, alpha=0.2)
            fig.tight_layout()
            fig.savefig(scatter_path, dpi=200)
            plt.close(fig)
        else:
            test_mse, test_mae = float("nan"), float("nan")
    else:
        test_mse, test_mae = float("nan"), float("nan")

    model_path = run_dir / "model.pt"
    torch.save(model.state_dict(), model_path)
    print(f"Saved model weights to {model_path}")
    print(f"Metrics logged to {metrics_path}")
    if test_metrics_path is not None:
        print(f"Test metrics saved to {test_metrics_path}")
    if scatter_path is not None:
        print(f"Test scatter plot saved to {scatter_path}")
    print(f"Run artifacts stored in {run_dir}")


if __name__ == "__main__":
    main()
